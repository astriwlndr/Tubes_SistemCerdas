{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/astriwlndr/Tubes_SistemCerdas/blob/main/Main_EANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bty07JK9t5I",
        "outputId": "0ab84e5f-125b-4bca-adb4-d12ba291912a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"drive/My Drive/SISTEM CERDAS/TUBES\")"
      ],
      "metadata": {
        "id": "iNuJHYCV9tgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2IyJyce7R-Z"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WN-V4qQ7R-n"
      },
      "outputs": [],
      "source": [
        "# Memanggil Dependencies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from numpy import ndarray\n",
        "from typing import List\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score, accuracy_score, classification_report\n",
        "from IPython.display import clear_output\n",
        "\n",
        "RANDOM_SEED = 27"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93dU9LWT7R-3"
      },
      "source": [
        "# Persiapan Data\n",
        "\n",
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MUJa_bN7R-_"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('input/diabetesPreProcessed.csv')\n",
        "\n",
        "# Mengambil data pada kolom Outcome ke variabel target sebagai numpy Array\n",
        "dftarget = df['Outcome']\n",
        "target = dftarget.to_numpy()\n",
        "\n",
        "# Menghapus kolom Outcome untuk mengambil data seluruh features\n",
        "df = df.drop(columns=['Outcome'])\n",
        "\n",
        "# Seluruh data features disimpan ke dalam variabel data sebagai numpy Array\n",
        "data = df.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSbtVCvo7R_I"
      },
      "source": [
        "## Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VhmKlm17R_O"
      },
      "outputs": [],
      "source": [
        "# Standarisasi Data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "s = StandardScaler()\n",
        "data = s.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1yiO_uuY5ZN",
        "outputId": "e24e1198-6dd2-4332-a0ef-a4892e172ba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.85673808 -1.2077916  -0.55049215 ... -0.84789212 -0.36549248\n",
            "  -0.18495286]\n",
            " [-0.85673808 -1.07488121 -0.55049215 ... -0.6273846  -0.92991477\n",
            "  -1.03858142]\n",
            " [ 0.36187714 -0.17773605  0.1287734  ... -0.99489713 -0.82561934\n",
            "  -0.27031571]\n",
            " ...\n",
            " [ 0.66653095  2.28110625  1.65712087 ...  0.46045251 -0.58942089\n",
            "   2.80274711]\n",
            " [ 1.58049236  1.61655427  0.1287734  ...  1.70999514 -0.20598184\n",
            "   0.83940142]\n",
            " [-0.85673808  0.15453994 -1.0599413  ... -0.33337457 -0.37162751\n",
            "   1.18085284]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4JLxATb7R_T"
      },
      "source": [
        "## Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D22WEOts7R_Y"
      },
      "outputs": [],
      "source": [
        "# Split Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=RANDOM_SEED)\n",
        "\n",
        "# Mengubah data target menjadi array 2D\n",
        "y_train, y_test = y_train.reshape(-1, 1), y_test.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJf0nKzL7R_m",
        "outputId": "d47e55f7-ad1f-4435-968a-39d6e92a9ee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(604, 8) (152, 8) (604, 1) (152, 1)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chsnZXC67R_1"
      },
      "source": [
        "# Artificial Neural Network\n",
        "\n",
        "## Fungsi-fungsi bantuan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPxtMd5D7R_3"
      },
      "outputs": [],
      "source": [
        "# Fungsi-fungsi bantuan\n",
        "\n",
        "def assert_same_shape(array: ndarray,\n",
        "                      array_grad: ndarray):\n",
        "    assert array.shape == array_grad.shape, \\\n",
        "        '''\n",
        "        Kedua ndarray harus memiliki shape yang sama;\n",
        "        Shape dari ndarray pertama adalah {0}\n",
        "        dan shape dari ndarray kedua adalah {1}.\n",
        "        '''.format(tuple(array_grad.shape), tuple(array.shape))\n",
        "    \n",
        "    return None\n",
        "\n",
        "def permute_data(X, y):\n",
        "    '''\n",
        "    Permutasi acak urutan data dari input\n",
        "    '''\n",
        "    perm = np.random.permutation(X.shape[0])\n",
        "    return X[perm], y[perm]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crnEFaY37R_5"
      },
      "source": [
        "## Operation Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1p3s6F3n7R_6"
      },
      "outputs": [],
      "source": [
        "class Operation(object):\n",
        "    '''\n",
        "    Kelas abstrak atau base class untuk tiap operasi yang ada di dalam neural network.\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def forward(self, input_: ndarray):\n",
        "        '''\n",
        "        Menyimpan input ke dalam variabel self._input\n",
        "        Kemudian memanggil fungsi self._output()\n",
        "        '''\n",
        "        self.input_ = input_\n",
        "\n",
        "        self.output = self._output()\n",
        "\n",
        "        return self.output\n",
        "\n",
        "\n",
        "    def backward(self, output_grad: ndarray) -> ndarray:\n",
        "        '''\n",
        "        Memanggil fungsi self._input_grad()\n",
        "        Memeriksa shape sesuai dengan yang seharusnya\n",
        "        menggunakan fungsi bantuan assert_same_shape\n",
        "        '''\n",
        "        assert_same_shape(self.output, output_grad)\n",
        "\n",
        "        self.input_grad = self._input_grad(output_grad)\n",
        "\n",
        "        assert_same_shape(self.input_, self.input_grad)\n",
        "        return self.input_grad\n",
        "\n",
        "\n",
        "    def _output(self) -> ndarray:\n",
        "        '''\n",
        "        Fungsi _output didefinisikan dan disesuakan dalam setiap fungsi operasi masing-masing\n",
        "        '''\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "    def _input_grad(self, output_grad: ndarray) -> ndarray:\n",
        "        '''\n",
        "        Fungsi _input_grad didefinisikan dan disesuakan dalam setiap fungsi operasi masing-masing\n",
        "        '''\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5fLiYlo7R__"
      },
      "source": [
        "## ParamOperation Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ExFqxHb7SAA"
      },
      "outputs": [],
      "source": [
        "class ParamOperation(Operation):\n",
        "    '''\n",
        "    Kelas operasi dengan parameter.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, param: ndarray) -> ndarray:\n",
        "        super().__init__()\n",
        "        self.param = param\n",
        "\n",
        "    def backward(self, output_grad: ndarray) -> ndarray:\n",
        "        '''\n",
        "        Memanggil fungsi self._input_grad dan self._param_grad\n",
        "        Juga memeriksa shape sesuai dengan yang seharusnya\n",
        "        menggunakan fungsi bantuan assert_same_shape\n",
        "        '''\n",
        "\n",
        "        assert_same_shape(self.output, output_grad)\n",
        "\n",
        "        self.input_grad = self._input_grad(output_grad)\n",
        "        self.param_grad = self._param_grad(output_grad)\n",
        "\n",
        "        assert_same_shape(self.input_, self.input_grad)\n",
        "        assert_same_shape(self.param, self.param_grad)\n",
        "\n",
        "        return self.input_grad\n",
        "\n",
        "    def _param_grad(self, output_grad: ndarray) -> ndarray:\n",
        "        '''\n",
        "        Setiap subclass dari ParamOperation harus memiliki fungsi _param_grad\n",
        "        '''\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMTNoMEY7SAC"
      },
      "source": [
        "## Operasi-operasi spesifik\n",
        "### Perkalian weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sW-i9T757SAD"
      },
      "outputs": [],
      "source": [
        "class WeightMultiply(ParamOperation):\n",
        "    '''\n",
        "    Perkalian matriks dalam neural network\n",
        "    '''\n",
        "\n",
        "    def __init__(self, W: ndarray):\n",
        "        '''\n",
        "        inisisalisasi nilai self.param = W\n",
        "        '''\n",
        "        super().__init__(W)\n",
        "\n",
        "    def _output(self) -> ndarray:\n",
        "        '''\n",
        "        Menghitung nilai Output\n",
        "        '''\n",
        "        return np.dot(self.input_, self.param)\n",
        "\n",
        "    def _input_grad(self, output_grad: ndarray) -> ndarray:\n",
        "        '''\n",
        "        Menghitung nilai input gradient\n",
        "        '''\n",
        "        return np.dot(output_grad, np.transpose(self.param, (1, 0)))\n",
        "\n",
        "    def _param_grad(self, output_grad: ndarray)  -> ndarray:\n",
        "        '''\n",
        "        Menghitung nilai parameter gradient\n",
        "        '''        \n",
        "        return np.dot(np.transpose(self.input_, (1, 0)), output_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quKZ3xYi7SAF"
      },
      "source": [
        "### Penambahan Bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDWTklAV7SAF"
      },
      "outputs": [],
      "source": [
        "class BiasAdd(ParamOperation):\n",
        "    '''\n",
        "    Penghitungan proses penambahan bias\n",
        "    '''\n",
        "\n",
        "    def __init__(self,\n",
        "                 B: ndarray):\n",
        "        '''\n",
        "        Inisialisasi operasi nilai self.param B\n",
        "        Memastikan juga shape dari bias sesuai\n",
        "        '''\n",
        "        assert B.shape[0] == 1\n",
        "        \n",
        "        super().__init__(B)\n",
        "\n",
        "    def _output(self) -> ndarray:\n",
        "        '''\n",
        "        Menghitung nilai output\n",
        "        '''\n",
        "        return self.input_ + self.param\n",
        "\n",
        "    def _input_grad(self, output_grad: ndarray) -> ndarray:\n",
        "        '''\n",
        "        Menghitung nilai input gradient\n",
        "        '''\n",
        "        return np.ones_like(self.input_) * output_grad\n",
        "\n",
        "    def _param_grad(self, output_grad: ndarray) -> ndarray:\n",
        "        '''\n",
        "        Menghitung nilai paramater gradient\n",
        "        '''\n",
        "        param_grad = np.ones_like(self.param) * output_grad\n",
        "        return np.sum(param_grad, axis=0).reshape(1, param_grad.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQeMGKm-7SAG"
      },
      "source": [
        "### Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpptWnHf7SAH"
      },
      "outputs": [],
      "source": [
        "class Sigmoid(Operation):\n",
        "    '''\n",
        "    Fungsi aktivasi sigmoid\n",
        "    '''\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        '''Pass'''\n",
        "        super().__init__()\n",
        "\n",
        "    def _output(self) -> ndarray:\n",
        "        '''\n",
        "        Menghitung nilai output\n",
        "        '''\n",
        "        return 1.0/(1.0+np.exp(-1.0 * self.input_))\n",
        "\n",
        "    def _input_grad(self, output_grad: ndarray) -> ndarray:\n",
        "        '''\n",
        "        Menghitung input gradient\n",
        "        '''\n",
        "        sigmoid_backward = self.output * (1.0 - self.output)\n",
        "        input_grad = sigmoid_backward * output_grad\n",
        "        \n",
        "        return input_grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUQjP56d7SAI"
      },
      "source": [
        "### ReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JN761Pxa7SAJ"
      },
      "outputs": [],
      "source": [
        "class ReLU(Operation):\n",
        "    '''\n",
        "    Fungsi aktivasi ReLU\n",
        "    '''\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "    def _output(self) -> ndarray:\n",
        "        '''\n",
        "        Menghitung nilai output\n",
        "        '''\n",
        "        return np.clip(self.input_, 0, None)\n",
        "\n",
        "    def _input_grad(self, output_grad: ndarray) -> ndarray:\n",
        "        '''\n",
        "        Menghitung input gradient\n",
        "        '''\n",
        "        mask = self.output >= 0\n",
        "        return output_grad * mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zV9By1KP7SAK"
      },
      "source": [
        "### Linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHT1tR5W7SAL"
      },
      "outputs": [],
      "source": [
        "class Linear(Operation):\n",
        "    '''\n",
        "    Fungsi aktivasi linear\n",
        "    '''\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        '''Pass'''        \n",
        "        super().__init__()\n",
        "\n",
        "    def _output(self) -> ndarray:\n",
        "        '''Pass through'''\n",
        "        return self.input_\n",
        "\n",
        "    def _input_grad(self, output_grad: ndarray) -> ndarray:\n",
        "        '''Pass through'''\n",
        "        return output_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgcjXzS47SAL"
      },
      "outputs": [],
      "source": [
        "class Tanh(Operation):\n",
        "    '''\n",
        "    Hyperbolic tangent activation function\n",
        "    '''\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "    def _output(self) -> ndarray:\n",
        "        return np.tanh(self.input_)\n",
        "\n",
        "    def _input_grad(self, output_grad: ndarray) -> ndarray:\n",
        "\n",
        "        return output_grad * (1 - self.output * self.output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czqL69E37SAN"
      },
      "source": [
        "## Layer Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz4sOYgY7SAO"
      },
      "outputs": [],
      "source": [
        "class Layer(object):\n",
        "    '''\n",
        "    Layer neuron-neuron dalam Neural Network\n",
        "    '''\n",
        "\n",
        "    def __init__(self,\n",
        "                 neurons: int):\n",
        "        '''\n",
        "        Init nilai neuron \n",
        "        '''\n",
        "        self.neurons = neurons\n",
        "        self.first = True\n",
        "        self.params: List[ndarray] = []\n",
        "        self.param_grads: List[ndarray] = []\n",
        "        self.operations: List[Operation] = []\n",
        "\n",
        "    def _setup_layer(self, num_in: int) -> None:\n",
        "        '''\n",
        "        Fungsi _setup_layer diimplementasikan pada setiap layer (Dense CLass)\n",
        "        '''\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def forward(self, input_: ndarray) -> ndarray:\n",
        "        '''\n",
        "        Pass nilai input forward pada setiap operasi dalam layer\n",
        "        ''' \n",
        "        if self.first:\n",
        "            self._setup_layer(input_)\n",
        "            self.first = False\n",
        "\n",
        "        self.input_ = input_\n",
        "\n",
        "        for operation in self.operations:\n",
        "\n",
        "            input_ = operation.forward(input_)\n",
        "\n",
        "        self.output = input_\n",
        "\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, output_grad: ndarray) -> ndarray:\n",
        "        '''\n",
        "        Pass nilai output_grad backward pada setiap operasi dalam layer\n",
        "        Assert cek nilai shape sesuai\n",
        "        '''\n",
        "\n",
        "        assert_same_shape(self.output, output_grad)\n",
        "\n",
        "        for operation in reversed(self.operations):\n",
        "            output_grad = operation.backward(output_grad)\n",
        "\n",
        "        input_grad = output_grad\n",
        "        \n",
        "        self._param_grads()\n",
        "\n",
        "        return input_grad\n",
        "\n",
        "    def _param_grads(self) -> ndarray:\n",
        "        '''\n",
        "        Ekstrak nilai param_grads dari operasi yang ada pada layer\n",
        "        '''\n",
        "\n",
        "        self.param_grads = []\n",
        "        for operation in self.operations:\n",
        "            if issubclass(operation.__class__, ParamOperation):\n",
        "                self.param_grads.append(operation.param_grad)\n",
        "\n",
        "    def _params(self) -> ndarray:\n",
        "        '''\n",
        "        Ekstrak nilai _params dari operasi yang ada pada layer\n",
        "        '''\n",
        "\n",
        "        self.params = []\n",
        "        for operation in self.operations:\n",
        "            if issubclass(operation.__class__, ParamOperation):\n",
        "                self.params.append(operation.param)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjSNIw0p7SAP"
      },
      "source": [
        "## Dense Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57P251vF7SAP"
      },
      "outputs": [],
      "source": [
        "class Dense(Layer):\n",
        "    '''\n",
        "    Fully connected layer, inherits dari Layer Class\n",
        "    '''\n",
        "    def __init__(self,\n",
        "                 neurons: int,\n",
        "                 activation: Operation = Sigmoid()):\n",
        "        '''\n",
        "        Mengatur fungsi aktivasi pada saat inisialisasi, \n",
        "        secara default akan menggunakan fungsi sigmoid\n",
        "        '''\n",
        "        super().__init__(neurons)\n",
        "        self.activation = activation\n",
        "\n",
        "    def _setup_layer(self, input_: ndarray) -> None:\n",
        "        '''\n",
        "        Setup kondisi layer, mengatur nilai awal weight, bias, dan \n",
        "        operasi yang terdapat dalam layer\n",
        "        '''\n",
        "        if self.seed:\n",
        "            np.random.seed(self.seed)\n",
        "\n",
        "        self.params = []\n",
        "\n",
        "        # weights\n",
        "        self.params.append(np.random.randn(input_.shape[1], self.neurons))\n",
        "\n",
        "        # bias\n",
        "        self.params.append(np.random.randn(1, self.neurons))\n",
        "        \n",
        "        # Operation\n",
        "        self.operations = [WeightMultiply(self.params[0]),\n",
        "                           BiasAdd(self.params[1]),\n",
        "                           self.activation]\n",
        "\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOHPwjTA7SAQ"
      },
      "source": [
        "## Loss Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLZGYVwg7SAR"
      },
      "outputs": [],
      "source": [
        "class Loss(object):\n",
        "    '''\n",
        "    Base Class untuk penghitungan nilai Loss dari Neural Network\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        '''Pass'''\n",
        "        pass\n",
        "\n",
        "    def forward(self, prediction: ndarray, target: ndarray) -> float:\n",
        "        '''\n",
        "        Menghitung nilai loss\n",
        "        '''\n",
        "        assert_same_shape(prediction, target)\n",
        "\n",
        "        self.prediction = prediction\n",
        "        self.target = target\n",
        "\n",
        "        loss_value = self._output()\n",
        "\n",
        "        return loss_value\n",
        "\n",
        "    def backward(self) -> ndarray:\n",
        "        '''\n",
        "        Menghitung nilai gradient loss terhadap input\n",
        "        '''\n",
        "        self.input_grad = self._input_grad()\n",
        "\n",
        "        assert_same_shape(self.prediction, self.input_grad)\n",
        "\n",
        "        return self.input_grad\n",
        "\n",
        "    def _output(self) -> float:\n",
        "        '''\n",
        "        Setiap subclass dari Loss harus memiliki fungsi _output\n",
        "        '''\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def _input_grad(self) -> ndarray:\n",
        "        '''\n",
        "        Setiap subclass dari Loss harus memiliki fungsi _input_grad\n",
        "        '''\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK7JVBkl7SAS"
      },
      "source": [
        "## Mean Squared Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5QAHtNs7SAS"
      },
      "outputs": [],
      "source": [
        "class MeanSquaredError(Loss):\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        '''Pass'''\n",
        "        super().__init__()\n",
        "\n",
        "    def _output(self) -> float:\n",
        "        '''\n",
        "        Menghitung nilai squared error loss\n",
        "        '''\n",
        "        loss = (\n",
        "            np.sum(np.power(self.prediction - self.target, 2)) / \n",
        "            self.prediction.shape[0]\n",
        "        )\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def _input_grad(self) -> ndarray:\n",
        "        '''\n",
        "        Menghitung nilai gradient loss terhadap input\n",
        "        '''        \n",
        "\n",
        "        return 2.0 * (self.prediction - self.target) / self.prediction.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cggUwDBd7SAT"
      },
      "source": [
        "## Neural Network Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vL7jM2QV7SAU"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(object):\n",
        "    '''\n",
        "    Class untuk Neural Network\n",
        "    '''\n",
        "    def __init__(self, \n",
        "                 layers: List[Layer],\n",
        "                 loss: Loss,\n",
        "                 seed: int = 1) -> None:\n",
        "        '''\n",
        "        Atribut-atribut yang dibutuhkan, yaitu layers dan loss\n",
        "        '''\n",
        "        self.layers = layers\n",
        "        self.loss = loss\n",
        "        self.seed = seed\n",
        "        if seed:\n",
        "            for layer in self.layers:\n",
        "                setattr(layer, \"seed\", self.seed)        \n",
        "\n",
        "    def forward(self, x_batch: ndarray) -> ndarray:\n",
        "        '''\n",
        "        Pass data forward melalui seluruh layer yang ada\n",
        "        '''\n",
        "        x_out = x_batch\n",
        "        for layer in self.layers:\n",
        "            x_out = layer.forward(x_out)\n",
        "\n",
        "        return x_out\n",
        "\n",
        "    def backward(self, loss_grad: ndarray) -> None:\n",
        "        '''\n",
        "        Pass data backward melalui seluruh layer yang ada\n",
        "        '''\n",
        "\n",
        "        grad = loss_grad\n",
        "        for layer in reversed(self.layers):\n",
        "            grad = layer.backward(grad)\n",
        "\n",
        "        return None\n",
        "\n",
        "    def train_batch(self,\n",
        "                    x_batch: ndarray,\n",
        "                    y_batch: ndarray) -> float:\n",
        "        '''\n",
        "        Fungsi batch training \n",
        "        Memanggil fungsi forward\n",
        "        Hitung nilai Loss\n",
        "        Memanggil fungsi backward\n",
        "        '''\n",
        "        \n",
        "        predictions = self.forward(x_batch)\n",
        "\n",
        "        loss = self.loss.forward(predictions, y_batch)\n",
        "\n",
        "        self.backward(self.loss.backward())\n",
        "\n",
        "        return loss\n",
        "    \n",
        "    def params(self):\n",
        "        '''\n",
        "        Get nilai seluruh parameter dari neural network\n",
        "        '''\n",
        "        for layer in self.layers:\n",
        "            yield from layer.params\n",
        "\n",
        "    def param_grads(self):\n",
        "        '''\n",
        "        Get nilai gradient loss terhadap parameters neural network.\n",
        "        '''\n",
        "        for layer in self.layers:\n",
        "            yield from layer.param_grads    \n",
        "            \n",
        "    def getWeight(self, index):\n",
        "        '''\n",
        "        Get nilai weight dari atribut params berdasarkan indeks layer ke-n\n",
        "        '''\n",
        "        return self.layers[index].params[0]\n",
        "    \n",
        "    def getBias(self, index):\n",
        "        '''\n",
        "        Get nilai bias dari atribut params berdasarkan indeks layer ke-n\n",
        "        '''\n",
        "        return self.layers[index].params[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7vcQiwE7SAW"
      },
      "source": [
        "## Optimizer Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xn9Y9qZs7SAY"
      },
      "outputs": [],
      "source": [
        "class Optimizer(object):\n",
        "    '''\n",
        "    Base class untuk optimizer.\n",
        "    '''\n",
        "    def __init__(self,\n",
        "                 lr: float = 0.01):\n",
        "        '''\n",
        "        Setiap optimizer harus memiliki inisiasi nilai learning rate.\n",
        "        '''\n",
        "        self.lr = lr\n",
        "\n",
        "    def step(self) -> None:\n",
        "        '''\n",
        "        Setiap optimizer harus memiliki fungsi step.\n",
        "        '''\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24CPEh-97SAZ"
      },
      "source": [
        "### SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkIXiecY7SAZ"
      },
      "outputs": [],
      "source": [
        "class SGD(Optimizer):\n",
        "    '''\n",
        "    Stochastic gradient descent optimizer.\n",
        "    '''    \n",
        "    def __init__(self,\n",
        "                 lr: float = 0.01) -> None:\n",
        "        '''Pass'''\n",
        "        super().__init__(lr)\n",
        "\n",
        "    def step(self):\n",
        "        '''\n",
        "        Menyesuaikan nilai parameter dengan besaran nilai penyesuaian \n",
        "        berdasarkan nilai learning rate.\n",
        "        '''\n",
        "        for (param, param_grad) in zip(self.net.params(),\n",
        "                                       self.net.param_grads()):\n",
        "\n",
        "            param -= self.lr * param_grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu4yTKxq7SAa"
      },
      "source": [
        "## Trainer Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0vqQeds7SAa"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "from typing import Tuple\n",
        "\n",
        "class Trainer(object):\n",
        "    '''\n",
        "    Melakukan training pada model neural network\n",
        "    '''\n",
        "    def __init__(self,\n",
        "                 net: NeuralNetwork,\n",
        "                 optim: Optimizer) -> None:\n",
        "        '''\n",
        "        Memasukkan objek neural network dan optimizer sebagai atribut dari trainer\n",
        "        Kemudian mengatur objek neural network sebagai atribut dari optimizer\n",
        "        '''\n",
        "        self.net = net\n",
        "        self.optim = optim\n",
        "        self.best_loss = 1e9\n",
        "        setattr(self.optim, 'net', self.net)\n",
        "        \n",
        "    def generate_batches(self,\n",
        "                         X: ndarray,\n",
        "                         y: ndarray,\n",
        "                         size: int = 32) -> Tuple[ndarray]:\n",
        "        '''\n",
        "        Membuat beberapa batch untuk proses training\n",
        "        Memastikan banyaknya baris data pada features dan juga target prediksi sama\n",
        "        '''\n",
        "        assert X.shape[0] == y.shape[0], \\\n",
        "        '''\n",
        "        Banyaknya baris data pada features dan juga target prediksi harus sama\n",
        "        sedangkan features memiliki {0} baris dan target memiliki {1} baris\n",
        "        '''.format(X.shape[0], y.shape[0])\n",
        "\n",
        "        N = X.shape[0]\n",
        "\n",
        "        for ii in range(0, N, size):\n",
        "            X_batch, y_batch = X[ii:ii+size], y[ii:ii+size]\n",
        "\n",
        "            yield X_batch, y_batch\n",
        "\n",
        "            \n",
        "    def fit(self, X_train: ndarray, y_train: ndarray,\n",
        "            X_test: ndarray, y_test: ndarray,\n",
        "            epochs: int=100,\n",
        "            eval_every: int=10,\n",
        "            batch_size: int=32,\n",
        "            seed: int = 1,\n",
        "            restart: bool = True)-> None:\n",
        "        '''\n",
        "        Fit model neural network terhadap set data training sebanyak epoch yang telah ditentukan.\n",
        "        \"eval_every\" merupakan variabel yang digunakan untuk mengatur setiap berapa epoch model\n",
        "        akan dievaluasi, evaluasi dilakukan menggunakan set data testing.\n",
        "        '''\n",
        "\n",
        "        np.random.seed(seed)\n",
        "        if restart:\n",
        "            for layer in self.net.layers:\n",
        "                layer.first = True\n",
        "\n",
        "            self.best_loss = 1e9\n",
        "\n",
        "        for e in range(epochs):\n",
        "\n",
        "            if (e+1) % eval_every == 0:\n",
        "                # Menyimpan data model terakhir ke \"last_model\" apabila proses training \n",
        "                # berhenti lebih dulu karena hasil evaluasi nilai loss naik\n",
        "                last_model = deepcopy(self.net)\n",
        "\n",
        "            X_train, y_train = permute_data(X_train, y_train)\n",
        "\n",
        "            batch_generator = self.generate_batches(X_train, y_train,\n",
        "                                                    batch_size)\n",
        "\n",
        "            for ii, (X_batch, y_batch) in enumerate(batch_generator):\n",
        "\n",
        "                self.net.train_batch(X_batch, y_batch)\n",
        "\n",
        "                self.optim.step()\n",
        "\n",
        "            if (e+1) % eval_every == 0:\n",
        "\n",
        "                test_preds = self.net.forward(X_test)\n",
        "                loss = self.net.loss.forward(test_preds, y_test)\n",
        "                \n",
        "                # Jika nilai loss tetap menurun maka proses training terus lanjut\n",
        "                # Namun jika nilai loss naik, maka proses akan berhenti\n",
        "                if loss < self.best_loss:\n",
        "#                     print(f\"Validation loss after {e+1} epochs is {loss:.3f}\")\n",
        "                    self.best_loss = loss\n",
        "                else:\n",
        "                    print(f\"\"\"Loss increased after epoch {e+1}, final loss was {self.best_loss:.3f}, using the model from epoch {e+1-eval_every}\"\"\")\n",
        "                    self.net = last_model\n",
        "                    setattr(self.optim, 'net', self.net)\n",
        "                    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebgY3Dbt7SAc"
      },
      "source": [
        "## Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJ4vsAzZ7SAd"
      },
      "outputs": [],
      "source": [
        "def eval_classification(model: NeuralNetwork,\n",
        "                          X_test: ndarray,\n",
        "                          y_test: ndarray):\n",
        "    '''\n",
        "    Generate hasil prediksi classification dari model \n",
        "    menggunakan set data testing\n",
        "    '''\n",
        "    regressionPreds = model.forward(X_test)\n",
        "    regressionPreds = regressionPreds.reshape(-1, 1)\n",
        "    \n",
        "    classsificationPreds = np.array([])\n",
        "\n",
        "    for i in regressionPreds:\n",
        "        if i < 0.5:\n",
        "            classsificationPreds = np.append(classsificationPreds, [0])\n",
        "        else:\n",
        "            classsificationPreds = np.append(classsificationPreds, [1])\n",
        "            \n",
        "    return classsificationPreds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsQJdWPB7SAd"
      },
      "source": [
        "# Evolving Algorithm\n",
        "## Fungsi-fungsi bantuan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KH_fmbXI7SAe"
      },
      "outputs": [],
      "source": [
        "def neuronRandom(neuronList):\n",
        "    '''\n",
        "    Memilih jumlah N neuron dari NeuronList\n",
        "    ''' \n",
        "    return (random.choice(neuronList))\n",
        "\n",
        "\n",
        "def activationRandom(activationList):\n",
        "    '''\n",
        "    Memilih fungsi aktivasi yang akan digunakan dari ActivationList\n",
        "    ''' \n",
        "    return (random.choice(activationList))\n",
        "\n",
        "def lrRandom():\n",
        "    '''\n",
        "    Mendapatkan nilai acak antara 0.01 s.d. 0.2 untuk learning rate\n",
        "    '''\n",
        "    return round(random.uniform(0.01, 0.2), 2)\n",
        "\n",
        "def modelGenerator():\n",
        "    '''\n",
        "    Membuat / Generate model sebagai gen baru\n",
        "    ''' \n",
        "    nn = NeuralNetwork(layers=[Dense(neurons=neuronRandom(neuronList), activation=activationRandom(activationList)), \n",
        "                               Dense(neurons=1, activation=Sigmoid())], \n",
        "                       loss=MeanSquaredError(), \n",
        "                       seed=RANDOM_SEED)\n",
        "    return nn\n",
        "\n",
        "def calculateFitness(gen):\n",
        "    '''\n",
        "    Menghitung nilai fitness dari gen menggunakan metric accuracy\n",
        "    Argumen gen merupakan objek model neural network\n",
        "    ''' \n",
        "    testPreds = eval_classification(gen, X_test, y_test)\n",
        "    testAccuracy = (accuracy_score(testPreds, y_test))\n",
        "    \n",
        "    return testAccuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiz9A3R57SAe"
      },
      "source": [
        "## Fungsi Membuat Populasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gasxNH8O7SAe"
      },
      "outputs": [],
      "source": [
        "def createPopulation(nPopulation):\n",
        "    '''\n",
        "    Membuat populasi sebanyak nPopulation\n",
        "    ''' \n",
        "    population = dict([('gen', []),\n",
        "                       ('lr', []),\n",
        "                       ('trainer', []),\n",
        "                       ('fitness', [])])\n",
        "    \n",
        "    # Looping sebanyak nPopulation\n",
        "    for i in range (nPopulation): \n",
        "        \n",
        "        # Membuat gen baru dan menambahkannya ke dalam dict\n",
        "        newGen = modelGenerator()\n",
        "        population['gen'].append(newGen)\n",
        "        \n",
        "        # Mengacak nilai lr dan menambahkannya ke dalam dict\n",
        "        lrRand = lrRandom()\n",
        "        population['lr'].append(lrRand)\n",
        "        \n",
        "        # Membuat trainer berdasarkan gen model yang telah dibuat dan nilai lr yang telah diacak\n",
        "        trainer = Trainer(newGen, SGD(lr=lrRand))\n",
        "        \n",
        "        # Melakukan fitting dari trainer yang telah dibuat\n",
        "        trainer.fit(X_train, y_train, X_test, y_test,\n",
        "        epochs = maxEpochs,\n",
        "        eval_every = 1,\n",
        "        seed=RANDOM_SEED)\n",
        "        \n",
        "        # Memasukkan trainer ke dalam dict\n",
        "        population['trainer'].append(trainer)\n",
        "        \n",
        "        # Menghitung dan memasukkan nilai fitness dari gen yang telah di fitting\n",
        "        fitness = calculateFitness(newGen)\n",
        "        population['fitness'].append(fitness)\n",
        "\n",
        "    return population"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW98qqj_7SAf"
      },
      "source": [
        "## Fungsi Seleksi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOzZzz527SAf"
      },
      "outputs": [],
      "source": [
        "def selection(population):\n",
        "    '''\n",
        "    Melakukan seleksi dari performa gen yang ada di dalam populasi\n",
        "    ''' \n",
        "    parent1 = dict([('gen', []), ('lr', []), ('trainer', []), ('fitness', [])])\n",
        "    parent2 = dict([('gen', []), ('lr', []), ('trainer', []), ('fitness', [])])\n",
        "    \n",
        "    # Cari index dari data populasi dengan nilai fitness terbesar\n",
        "    max_index = np.argmax(np.asarray(population['fitness']), axis=0)\n",
        "    \n",
        "    #  Simpan data tersebut sebagai parent1\n",
        "    parent1['gen'] = population['gen'][max_index]\n",
        "    parent1['lr'] = population['lr'][max_index]\n",
        "    parent1['trainer'] = population['trainer'][max_index]\n",
        "    parent1['fitness'] = population['fitness'][max_index]\n",
        "    \n",
        "    # Simpan data tertinggi ke tmp, untuk di pop terlebih dahulu\n",
        "    tmp_index = max_index\n",
        "    tmp_gen = population['gen'][max_index]\n",
        "    tmp_lr = population['lr'][max_index]\n",
        "    tmp_trainer = population['trainer'][max_index]\n",
        "    tmp_fitness = population['fitness'][max_index]\n",
        "    \n",
        "    # Pop data tertinggi untuk proses mencari data tertinggi ke 2\n",
        "    population['gen'].pop(max_index)\n",
        "    population['lr'].pop(max_index)\n",
        "    population['trainer'].pop(max_index)\n",
        "    population['fitness'].pop(max_index)\n",
        "    \n",
        "    # Cari index dari data dengan fitness tertinggi ke 2\n",
        "    max_index = np.argmax(np.asarray(population['fitness']), axis=0)\n",
        "    \n",
        "    #  Simpan sebagai parent2\n",
        "    parent2['gen'] = population['gen'][max_index]\n",
        "    parent2['lr'] = population['lr'][max_index]\n",
        "    parent2['trainer'] = population['trainer'][max_index]\n",
        "    parent2['fitness'] = population['fitness'][max_index]\n",
        "    \n",
        "    # Kembalikan data di tmp ke populasi di index tmp\n",
        "    population['gen'].insert(tmp_index, tmp_gen)\n",
        "    population['lr'].insert(tmp_index, tmp_lr)\n",
        "    population['trainer'].insert(tmp_index, tmp_trainer)\n",
        "    population['fitness'].insert(tmp_index, tmp_fitness)\n",
        "    \n",
        "    print(\"parent1: \", parent1['gen'].layers[0].neurons, parent1['lr'], parent1['fitness'], parent1['gen'].layers[0].activation)\n",
        "    print(\"parent2: \", parent2['gen'].layers[0].neurons, parent2['lr'], parent2['fitness'], parent2['gen'].layers[0].activation)\n",
        "    return [parent1, parent2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y80LLCF7SAf"
      },
      "source": [
        "## Fungsi Crossover"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yb3sTbkS7SAg"
      },
      "outputs": [],
      "source": [
        "def crossover(parents):\n",
        "    '''\n",
        "    Melakukan crossover dari parents untuk membuat child\n",
        "    ''' \n",
        "    child1 = dict([('gen', []), ('lr', []), ('trainer', []), ('fitness', [])])\n",
        "    child2 = dict([('gen', []), ('lr', []), ('trainer', []), ('fitness', [])])\n",
        "    \n",
        "    # status untuk menandakan kondisi banyaknya neuron dari hidden layer milik parent\n",
        "    # crossoverStatus bernilai 0 jika banyaknya neuron dari kedua parent berbeda    \n",
        "    crossoverStatus = 0\n",
        "    \n",
        "    # Proses ketika banyaknya neuron dari kedua parent sama\n",
        "    if parents[0]['gen'].layers[0].neurons == parents[1]['gen'].layers[0].neurons:\n",
        "        # crossoverStatus bernilai 1 jika banyaknya neuron dari kedua parent sama\n",
        "        crossoverStatus = 1\n",
        "        \n",
        "        # Data dari kedua parent dimasukkan ke dalam dict child\n",
        "        child1['gen'] = deepcopy(parents[0]['gen'])\n",
        "        child2['gen'] = deepcopy(parents[1]['gen'])\n",
        "        \n",
        "        # Ambil length dari array features milik input dengan shape \n",
        "        # kemudian bagi 2 nilai tersebut untuk memecah array weight menjadi 2 bagian\n",
        "        # simpan nilai ke Crossover Point (CP)\n",
        "        CP = parents[0]['gen'].layers[0].params[0].shape[0] // 2\n",
        "        \n",
        "        # Nilai weight dari child1 adalah setengah nilai weight awal dari parent[0]\n",
        "        # dan setengah nilai weight akhir dari parent[1]\n",
        "        child1Weights = np.concatenate((parents[0]['gen'].layers[0].params[0][:CP], \n",
        "                                        parents[1]['gen'].layers[0].params[0][CP:]),axis = 0)\n",
        "        \n",
        "        # Nilai weight dari child2 adalah setengah nilai weight awal dari parent[1]\n",
        "        # dan setengan nilai weight akhir dari parent[0]\n",
        "        child2Weights = np.concatenate((parents[1]['gen'].layers[0].params[0][:CP],\n",
        "                                        parents[0]['gen'].layers[0].params[0][CP:]),axis = 0)\n",
        "        \n",
        "        \n",
        "        # Ambil length dari array bias (sama seperti jumlah neurons di hidden layer)\n",
        "        # kemudian bagi 2 nilai tersebut untuk memecah array bias menjadi 2 bagian\n",
        "        # simpan nilai ke Crossover Point (CP)\n",
        "        CP = parents[0]['gen'].layers[0].params[1].shape[1] // 2\n",
        "        \n",
        "        # Nilai bias dari child1 adalah setengah nilai bias awal dari parent[0]\n",
        "        # dan setengah nilai bias akhir dari parent[1]\n",
        "        bias = np.concatenate((parents[0]['gen'].layers[0].params[1][0][:CP], \n",
        "                               parents[1]['gen'].layers[0].params[1][0][CP:]),axis = 0)\n",
        "        child1Bias = np.array([bias])\n",
        "\n",
        "        # Nilai bias dari child2 adalah setengah nilai bias awal dari parent[1]\n",
        "        # dan setengah nilai bias akhir dari parent[0]\n",
        "        bias = np.concatenate((parents[1]['gen'].layers[0].params[1][0][:CP],\n",
        "                                parents[0]['gen'].layers[0].params[1][0][CP:]),axis = 0)\n",
        "        child2Bias = np.array([bias])\n",
        "        \n",
        "        # Masukkan nilai weight dan bias ke child1\n",
        "        child1['gen'].layers[0].params[0] = child1Weights\n",
        "        child1['gen'].layers[0].params[1] = child1Bias\n",
        "        \n",
        "        # Masukkan nilai weight dan bias ke child2\n",
        "        child2['gen'].layers[0].params[0] = child2Weights\n",
        "        child2['gen'].layers[0].params[1] = child2Bias\n",
        "        \n",
        "        # Fungsi aktivasi dan Learning rate child1 milik parent[1]\n",
        "        child1['gen'].layers[0].activation = parents[1]['gen'].layers[0].activation        \n",
        "        child1['lr'] = parents[1]['lr']\n",
        "        child1['trainer'] = Trainer(child1['gen'], SGD(lr=child1['lr']))\n",
        "        \n",
        "        # Fungsi aktivasi dan Learning rate child2 milik parent[0]\n",
        "        child2['gen'].layers[0].activation = parents[0]['gen'].layers[0].activation\n",
        "        child2['lr'] = parents[0]['lr']\n",
        "        child2['trainer'] = Trainer(child2['gen'], SGD(lr=child2['lr']))\n",
        "        \n",
        "        \n",
        "        # Hitung kembali fitness kedua child setelah crossover\n",
        "        child1['fitness'] = calculateFitness(child1['gen'])\n",
        "        child2['fitness'] = calculateFitness(child2['gen'])\n",
        "        \n",
        "    # Proses ketika banyaknya neuron dari kedua parent tidak sama\n",
        "    # Tidak ada penyilangan weight dan bias, karena shape keduanya berbeda\n",
        "    else:\n",
        "        \n",
        "        # Fungsi aktivasi dan Learning rate child1 milik parent[1]\n",
        "        child1['gen'] = deepcopy(parents[0]['gen'])\n",
        "        child1['gen'].layers[0].activation = parents[1]['gen'].layers[0].activation\n",
        "        child1['lr'] = parents[1]['lr']\n",
        "        child1['trainer'] = Trainer(child1['gen'], SGD(lr=child1['lr']))\n",
        "        \n",
        "        # Fungsi aktivasi dan Learning rate child1 milik parent[0]\n",
        "        child2['gen'] = deepcopy(parents[1]['gen'])\n",
        "        child2['gen'].layers[0].activation = parents[0]['gen'].layers[0].activation\n",
        "        child2['lr'] = parents[0]['lr']\n",
        "        child2['trainer'] = Trainer(child2['gen'], SGD(lr=child2['lr']))\n",
        "        \n",
        "        # Hitung kembali fitness kedua child setelah crossover\n",
        "        child2['fitness'] = calculateFitness(child2['gen'])\n",
        "        child1['fitness'] = calculateFitness(child1['gen'])\n",
        "    \n",
        "    print(\"child1: \", child1['gen'].layers[0].neurons, child1['lr'], child1['fitness'], child1['gen'].layers[0].activation)\n",
        "    print(\"child2: \", child2['gen'].layers[0].neurons, child2['lr'], child2['fitness'], child2['gen'].layers[0].activation)\n",
        "    return [child1, child2, crossoverStatus]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiLE4xU77SAg"
      },
      "source": [
        "## Fungsi Mutasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dERWEqtM7SAg"
      },
      "outputs": [],
      "source": [
        "def mutation(child, mutationRate):\n",
        "    '''\n",
        "    Proses mutasi kedua child yang dihasilkan dari proses crossover\n",
        "    ''' \n",
        "    # Tambah key baru mutationLog ke dalam dict mutant \n",
        "    # untuk mencatat mutasi apa saja yang terjadi dalam fungsi ini\n",
        "    mutant1 = child[0]\n",
        "    mutant1['mutationLog'] = dict([('neuronUpdated', 0), ('activationUpdated', 0), ('lrUpdated', 0)])\n",
        "    mutant2 = child[1]\n",
        "    mutant2['mutationLog'] = dict([('neuronUpdated', 0), ('activationUpdated', 0), ('lrUpdated', 0)])\n",
        "    \n",
        "    # Jadikan data kedua mutant sebagai list\n",
        "    mutants = [mutant1, mutant2]\n",
        "    \n",
        "    # Loop kedua Mutant dalam list untuk proses mutasi\n",
        "    for i in range(2):\n",
        "        '''\n",
        "        mutationRate adalah ambang batas kemungkinan untuk terjadinya mutasi pada mutant\n",
        "        \n",
        "        Dihasilkan nilai acak antara 0 dan 1, kemudian mutasi akan terjadi apabila\n",
        "        nilai random yang dihasilkan lebih kecil dari mutationRate\n",
        "        \n",
        "        Sehingga probabilitas terjadinya mutasi akan lebih besar apabila\n",
        "        nilai dari mutationRate semakin besar\n",
        "        ''' \n",
        "        # Mutasi banyaknya neuron dengan mengambil banyaknya neuron dari neuronList\n",
        "        if random.random() <= mutationRate:\n",
        "            mutants[i]['gen'].layers[0].neurons = neuronRandom(neuronList)\n",
        "            mutants[i]['mutationLog']['neuronUpdated'] = 1\n",
        "            \n",
        "        # Mutasi fungsi aktivasi dengan mengambil dari activationList\n",
        "        if random.random() <= mutationRate:\n",
        "            randDifStatus = True\n",
        "            while randDifStatus == True:\n",
        "                actRand = activationRandom(activationList)\n",
        "                # print(\"actRand\", actRand) \n",
        "                # print(\"mutAct\", mutants[i]['gen'].layers[0].activation)\n",
        "                if actRand != mutants[i]['gen'].layers[0].activation:\n",
        "                    mutants[i]['gen'].layers[0].activation = actRand\n",
        "                    randDifStatus = False\n",
        "                    mutants[i]['mutationLog']['activationUpdated'] = 1\n",
        "                    # print(f\"mutasi aktivasi {i}\", mutants[i]['gen'].layers[0].activation)\n",
        "        \n",
        "        # Mutasi Learning Rate dengan fungsi bantuan lrRandom\n",
        "        if random.random() <= mutationRate:\n",
        "            mutants[i]['lr'] = lrRandom()\n",
        "            mutants[i]['mutationLog']['lrUpdated'] = 1\n",
        "            \n",
        "        # Memasukkan trainer baru berdasarkan atribut yang dimiliki\n",
        "        # kemudian fitting mutant dan hitung nilai fitness-nya\n",
        "        mutants[i]['trainer'] = Trainer(mutants[i]['gen'], SGD(lr=mutants[i]['lr']))\n",
        "        mutants[i]['trainer'].fit(X_train, y_train, X_test, y_test,\n",
        "                                 epochs = maxEpochs,\n",
        "                                 eval_every = 1,\n",
        "                                 seed=RANDOM_SEED)\n",
        "        mutants[i]['fitness'] = calculateFitness(mutants[i]['gen'])\n",
        "    \n",
        "    print(\"mutant1: \", mutants[0]['gen'].layers[0].neurons, mutants[0]['lr'], mutants[0]['fitness'], mutants[0]['gen'].layers[0].activation)\n",
        "    print(\"mutant2: \", mutants[1]['gen'].layers[0].neurons, mutants[1]['lr'], mutants[1]['fitness'], mutants[1]['gen'].layers[0].activation)\n",
        "    return mutants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn-UDd1o7SAh"
      },
      "source": [
        "## Fungsi Regenerasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Bef-4e37SAh"
      },
      "outputs": [],
      "source": [
        "def regeneration(mutants, population):\n",
        "    '''\n",
        "    Proses regenerasi untuk menghapus gen dengan fitness terkecil di dalam populasi\n",
        "    Kemudian memasukkan mutant baru yang dihasilkan dari proses mutasi\n",
        "    ''' \n",
        "    # Loop kedua mutant\n",
        "    for i in range(2):\n",
        "        # Cari index dari data populasi dengan fitness terkecil\n",
        "        min_index = np.argmin(np.asarray(population['fitness']), axis=0)\n",
        "        \n",
        "        # Jika data dengan fitness terkecil dari populasi lebih kecil dari fitness mutant\n",
        "#         if population['fitness'][min_index] < mutants[i]['fitness']:\n",
        "        # Maka gen populasi tersebut dihapus\n",
        "        population['gen'].pop(min_index)\n",
        "        population['lr'].pop(min_index)\n",
        "        population['trainer'].pop(min_index)\n",
        "        population['fitness'].pop(min_index)\n",
        "\n",
        "        # Kemudian menambah populasi dengan data mutant baru\n",
        "        population['gen'].append(mutants[i]['gen'])\n",
        "        population['lr'].append(mutants[i]['lr'])\n",
        "        population['trainer'].append(mutants[i]['trainer'])\n",
        "        population['fitness'].append(mutants[i]['fitness'])\n",
        "\n",
        "    return population"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JH5L9Oy7SAh"
      },
      "source": [
        "## Fungsi Terminasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OcYVjRp7SAi"
      },
      "outputs": [],
      "source": [
        "def termination(population, fitnessTarget, generation, nGeneration):\n",
        "    \n",
        "    # Cari index dari data dengan fitness tertinggi\n",
        "    max_index = np.argmax(np.asarray(population['fitness']), axis=0)\n",
        "    \n",
        "    # Cek apakah nilai fitness terbaik di dalam populasi sudah mencapai fitness target\n",
        "    if population['fitness'][max_index] > fitnessTarget:\n",
        "        # Jika sudah tercapai maka ubah isLooping menjadi False\n",
        "        isLooping = False        \n",
        "        \n",
        "    else:\n",
        "        # Jika belum tercapai maka isLooping tetap True\n",
        "        isLooping = True\n",
        "    \n",
        "    # Cek juga apakah proses evolusi sudah mencapai batas maksimum generasi\n",
        "    if generation >= nGeneration:\n",
        "        # Jika sudah tercapai maka ubah isGenerating menjadi False\n",
        "        isGenerating = False\n",
        "        \n",
        "    else:\n",
        "        # Jika belum tercapai maka isGenerating tetap True\n",
        "        isGenerating = True\n",
        "\n",
        "    # return variabel solusi\n",
        "    return {'max_index':max_index, 'isLooping':isLooping, 'isGenerating':isGenerating}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9JWuZ607SAi"
      },
      "source": [
        "# Pelatihan dan Pengujian Algoritma\n",
        "\n",
        "## Inisiasi variabel konfigurasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDScU--t7SAi"
      },
      "outputs": [],
      "source": [
        "neuronList = [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]\n",
        "activationList = [Sigmoid(), ReLU(), Linear(), Tanh()]\n",
        "maxEpochs = 2000\n",
        "\n",
        "nPopulation = 10\n",
        "nGeneration = 100\n",
        "mutationRate = 0.5\n",
        "\n",
        "fitnessTarget = 0.85\n",
        "isLooping = True\n",
        "isGenerating = True\n",
        "\n",
        "random.seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S0zIdhA7SAi"
      },
      "source": [
        "## Pelatihan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDBRTzFa7SAi",
        "outputId": "77aa2af9-b133-4078-977b-87619581042d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generasi ke: \n",
            "100\n",
            "\n",
            "Data Gen Terbaik\n",
            "Indeks: \n",
            "7\n",
            "\n",
            "Banyaknya Neuron: \n",
            "16\n",
            "\n",
            "Learning rate: \n",
            "0.02\n",
            "\n",
            "Fungsi Aktivasi: \n",
            "<__main__.Tanh object at 0x7f8233c59950>\n",
            "\n",
            "Fitness: \n",
            "0.8355263157894737\n",
            "\n",
            "========\n",
            "Proses: \n",
            "Seleksi...\n",
            "parent1:  16 0.02 0.8355263157894737 <__main__.Tanh object at 0x7f8233c59950>\n",
            "parent2:  32 0.04 0.8092105263157895 <__main__.Tanh object at 0x7f8233c59950>\n",
            "Crossover...\n",
            "child1:  16 0.04 0.8355263157894737 <__main__.Tanh object at 0x7f8233c59950>\n",
            "child2:  32 0.02 0.8092105263157895 <__main__.Tanh object at 0x7f8233c59950>\n",
            "Mutasi...\n",
            "Loss increased after epoch 74, final loss was 0.190, using the model from epoch 73\n",
            "Loss increased after epoch 87, final loss was 0.168, using the model from epoch 86\n",
            "mutant1:  16 0.04 0.7763157894736842 <__main__.ReLU object at 0x7f8233c4a950>\n",
            "mutant2:  32 0.16 0.7960526315789473 <__main__.Tanh object at 0x7f8233c59950>\n",
            "Regenerasi...\n",
            "\n",
            "========\n",
            "\n",
            "Generasi Maksimum Tercapai\n",
            "CPU times: user 9min 11s, sys: 5min 47s, total: 14min 59s\n",
            "Wall time: 8min 29s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import time\n",
        "\n",
        "print(f\"Inisiasi {nPopulation} Populasi Awal...\")\n",
        "population = createPopulation(nPopulation)\n",
        "\n",
        "generation = 1\n",
        "while isLooping and isGenerating:\n",
        "    # Membersihkan output dari generasi sebelumnya pada console jupyter notebook\n",
        "    clear_output(wait=True)\n",
        "    \n",
        "    # Memeriksa populasi dengan fungsi terminasi\n",
        "    solution = termination(population, fitnessTarget, generation, nGeneration)\n",
        "    \n",
        "    # Update nilai parameter kondisi while berdasarkan output fungsi terminasi\n",
        "    isLooping = solution['isLooping']\n",
        "    isGenerating = solution['isGenerating']\n",
        "    \n",
        "    # Ambil nilai index dari gen terbaik pada generasi ke-i\n",
        "    max_index = solution['max_index']\n",
        "    \n",
        "    # Output atribut-atribut dari gen terbaik\n",
        "    print(\"Generasi ke: \")\n",
        "    print(generation)\n",
        "    print()\n",
        "    print(\"Data Gen Terbaik\")\n",
        "    print(\"Indeks: \")\n",
        "    print(max_index)\n",
        "    print()\n",
        "    \n",
        "    print(\"Banyaknya Neuron: \")\n",
        "    print(population['gen'][max_index].layers[0].neurons)\n",
        "    print()\n",
        "    \n",
        "    print(\"Learning rate: \")\n",
        "    print(population['lr'][max_index])\n",
        "    print()\n",
        "    \n",
        "    print(\"Fungsi Aktivasi: \")\n",
        "    print(population['gen'][max_index].layers[0].activation)\n",
        "    print()\n",
        "    \n",
        "    print(\"Fitness: \")\n",
        "    print(population['fitness'][max_index])\n",
        "    print()\n",
        "    \n",
        "    print(\"========\")\n",
        "    \n",
        "    # Memulai proses evolusi pada populasi\n",
        "    print(\"Proses: \")\n",
        "    \n",
        "    # Melakukan seleksi\n",
        "    print(\"Seleksi...\")\n",
        "    parents = selection(population)\n",
        "    \n",
        "    # Melakukan crossover\n",
        "    print(\"Crossover...\")\n",
        "    childs = crossover(parents)\n",
        "    \n",
        "    # Melakukan mutasi\n",
        "    print(\"Mutasi...\")\n",
        "    mutants = mutation(childs, mutationRate)\n",
        "    \n",
        "    # Melakukam regenerasi\n",
        "    print(\"Regenerasi...\")\n",
        "    population = regeneration(mutants, population)\n",
        "    print()\n",
        "    \n",
        "    print(\"========\")\n",
        "    print()\n",
        "    \n",
        "    # Iterasi generasi\n",
        "    generation += 1\n",
        "        \n",
        "# Cek berhentinya proses evolusi\n",
        "if not isLooping:\n",
        "    # Jika karena target nilai fitness tercapai\n",
        "    print(\"Fitness Target Tercapai\")\n",
        "    \n",
        "if not isGenerating:\n",
        "    # Jika karena generasi maksimum telah tercapai\n",
        "    print(\"Generasi Maksimum Tercapai\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZMppqGd7SAj"
      },
      "source": [
        "### Pengukuran Performa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwLHjx3J7SAk",
        "outputId": "453b7709-26a9-4915-b4ff-834d76e62cba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[89 16]\n",
            " [ 9 38]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.85      0.88       105\n",
            "           1       0.70      0.81      0.75        47\n",
            "\n",
            "    accuracy                           0.84       152\n",
            "   macro avg       0.81      0.83      0.81       152\n",
            "weighted avg       0.84      0.84      0.84       152\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "print(\"Confusion Matrix:\")\n",
        "y_pred = eval_classification(population['gen'][max_index], X_test, y_test)\n",
        "cm = confusion_matrix(y_test, y_pred) \n",
        "print(cm)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "f, ax = plt.subplots(figsize=(8,5))\n",
        "sns.heatmap(cm, annot=True, fmt=\".0f\", ax=ax)\n",
        "plt.xlabel(\"Prediksi\")\n",
        "plt.ylabel(\"Nilai Aktual\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX1dUOS37SAk"
      },
      "source": [
        "### Menyimpan Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2GbgmAG7SAl"
      },
      "outputs": [],
      "source": [
        "# Menyimpan nilai output bernilai riil\n",
        "np.savetxt('output/output2.txt', population['gen'][max_index].layers[1].output, delimiter=',', fmt='%1.5f')\n",
        "\n",
        "# Menyimpan nilai output Prediksi akhir\n",
        "testPreds = eval_classification(population['gen'][max_index], X_test, y_test)\n",
        "np.savetxt('output/output3.txt', testPreds, delimiter=',', fmt='%i')\n",
        "\n",
        "# Menyimpan nilai weight dan bias pada layer 0 (hidden layer)\n",
        "weights0 = population['gen'][max_index].layers[0].params[0]\n",
        "bias0 = population['gen'][max_index].layers[0].params[1]\n",
        "np.savetxt('output/weights2.txt', weights0, delimiter=',')\n",
        "np.savetxt('output/bias2.txt', bias0, delimiter=',')\n",
        "\n",
        "# Menyimpan nilai weight dan bias pada layer 1 (output layer)\n",
        "weights1 = population['gen'][max_index].layers[1].params[0]\n",
        "bias1 = population['gen'][max_index].layers[1].params[1]\n",
        "np.savetxt('output/weights3.txt', weights1, delimiter=',')\n",
        "np.savetxt('output/bias3.txt', bias1, delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WzJYX53c-V3h"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "Main EANN.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}